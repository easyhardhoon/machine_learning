{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "ML14.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyPCyf5+xHFhAeZz7/N3T5/C",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/easyhardhoon/machine_learning/blob/master/ML14.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#합성곱 신경망 : CNN\n",
        "\n",
        "계층에 관하여\n",
        "\n",
        "+ Affine 계층 :Affine  + (활성화함수) 의 형식.(완전연결 계층이라고도 부른다)\n",
        "\n",
        "+ CNN : conv + (활성화함수) + Pooling 의 형식.  pooling은 생략가능합니다\n",
        "\n",
        "  (conv : 합성곱 계층. pooling : 풀링 계층)\n",
        "\n",
        "+ 또한 CNN의 후반부에는 그대로 Affine + 활성화함수의 조합을 사용합니다\n",
        "\n",
        "#CNN의 특징\n",
        "\n",
        "완전연결 신경망과 달리 3차원 데이터 같은 입체적인 데이터가 흐릅니다\n",
        "\n",
        "사실 MNIST 데이터셋의 사례에서는 형상이 (1,28,28)인 이미지(1채널, 세로 28픽셀,가로 28픽셀) 를 1줄로 세운 784개의 데이터(1차원)으로 Affine  계층에 입력했다\n",
        "\n",
        "(3차원 데이터를 1차원 데이터로 평탄화함)\n",
        "\n",
        "**하지만** \n",
        "\n",
        "이미지는 3차원 형상이며, 이 형상에는 소중한 공간적 정보가 들어있다\n",
        "\n",
        "**3차원 속에서 의미를 갖는 본질적인 패턴**이 숨어있을텐데,\n",
        "\n",
        "완전연결 계층은 이런형상을 무시하고 모든 입력 데이터를 동등한 뉴런(같은 차원)으로 취급하여 형상에 담긴 정보를 살릴 수 없다.\n",
        "\n",
        "CNN에서는 이러한 형상의 유지가 가능하다\n",
        "\n",
        "CNN에서는 합성곱 계층의 입출력 데이터를 **특징 맵**이라고도 한다.\n"
      ],
      "metadata": {
        "id": "csUPl2TtHV0v"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 합성곱 연산\n",
        "\n",
        "Affine 계층에서의 연산이 행렬dot의 느낌이었다면, 여기 conv 계층(합성곱 계층)에서도 고유의 연산법이 있을 것이다.\n",
        "\n",
        "필터 연산이라고도 한다\n",
        "\n",
        "합성곱 연산은, 입력 데이터에 필터(커널)를 적용한 결과이다.\n",
        "\n",
        "필터의 윈도우를 일정 간격으로 이동해가며 입력 데이터에 적용한다\n",
        "\n",
        "ex) 입력 (4,4) , 필터(3,3), 출력(2,2) \n",
        "\n",
        "완전연결 신경망에서는 가중치 매개변수와 편향이 존재했다(Affine 연산 논리)\n",
        "\n",
        "CNN에서도 필터의 매개변수가 가중치에 해당하고, 편향도 똑같이 존재한다\n",
        "\n",
        "(편향은 필터를 적용한 후의 데이터에 더해지고, 항상 하나(1*1)만 존재한다)"
      ],
      "metadata": {
        "id": "IrgjLXrQSTMe"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#합성곱 연산의 skill들\n",
        "\n",
        "+ padding\n",
        "\n",
        "  --> 합성곱 연산을 수행하기 전에 입력 데이터 주변을 특정 값(0)으로 채우는 기법\n",
        "\n",
        "  ex) (4,4)의 입력 데이터에 패딩 : 1을 입력하면 (6,6)의 크기가 되고 (3,3)의 \n",
        "  필터를 거쳐 (4,4)의 출력 데이터를 생성한다. \n",
        "\n",
        "  ex) 패딩 : 3을 입력하면 (10,10)의 크기가 된다. 이러한 패딩은 출력 크기를 \n",
        "  조정할 목적으로 쓰인다\n",
        "\n",
        "  입력 데이터의 공간적 크기를 고정한 채로 다음 계층에 전달할 수도 있고, 합성곱 \n",
        "  연산을 몇번이나 되풀이하는 심층 신경망에서 효과적인 방법이다.\n",
        "\n",
        "+ stride\n",
        "\n",
        "  ---> 필터를 적용하는 위치의 간격. \n",
        "\n",
        "  ex) 스트라이드 :2를 입력하면 필터를 적용하는 윈도우가 두 칸 씩 이동한다\n",
        "\n",
        "\n",
        "#두 스킬과 출력의 상관관계\n",
        "\n",
        "스트라이드를 키우면 출력 크기는 작아진다\n",
        "\n",
        "패딩을 크게 하면 출력 크기는 커진다\n",
        "\n",
        "입력 크기를 (H,W), 필터 크기를 (FH,FW), 출력 크기를 (OH,OW), 패딩을 P, 스트라이드를 S라 하면\n",
        "\n",
        "OH = ( H + 2P - FH ) / S + 1\n",
        "\n",
        "OW = ( W + 2P - FW ) / S + 1"
      ],
      "metadata": {
        "id": "DqK6F6f1Yhux"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 3차원 데이터의 합성곱 연산\n",
        "\n",
        "지금까지는 2차원이었지만, 합성곱은 신경망은 3차원이 가능하다는 점을 상기하자.\n",
        "\n",
        "2차원일때와 기본 로직은 같다.\n",
        "\n",
        "2차원때와 비교하면 길이 방향으로 특징 맵이 늘어났다.\n",
        "\n",
        "채녈(길이) 쪽으로 특징 맵이 여러 개 있다면 입력 데이터와 필터의 합성곱 연산을 채널마다 수행하고 \n",
        "\n",
        "그 결과를 더해서 **하나의 출력**을 얻는다\n",
        "\n",
        "✈주의할 점\n",
        "\n",
        "필터의 채널 수와 입력 데이터의 채널 수가 같아야 한다.\n",
        "\n",
        "✈TIP\n",
        "\n",
        "데이터와 필터를 직육면체 블록이라고 생각하면 쉽다\n",
        "\n",
        "  + 3차원 데이터를 다차원 배열로 나타낼 때 : (채널,높이,너비)\n",
        "\n",
        "  mnist의 채널에는 \"색상\"의 정보가 들어갔다 \n",
        "\n",
        "  + 정리 : **(C, H, W) * (C,FH,FW) = (1, OH, OW)**"
      ],
      "metadata": {
        "id": "VnMYNu4PEpW4"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 출력 데이터(출력 특징 맵)를 여러개(다수의 채널)로 하고 싶다면\n",
        "\n",
        "--> 필터(가중치)를 다수 사용한다\n",
        "\n",
        "(C,H,W) --> **(FN, C, FH, FW)** --> (FN, OH, OW)\n",
        "\n",
        "각각의 (C, FH, FW) 필터 블록 \"FN\"개 라고 생각하자.\n",
        "\n",
        "이처럼 필터의 가중치 데이터를 4차원으로 하면\n",
        "\n",
        "(출력 채널수 , 입력 채널수, 높이, 너비)\n",
        "\n",
        "출력 데이터를 여러개로 구현 가능.\n",
        "\n",
        "✈ 편향 : 마찬가지로 (FN,1,1)의 형상. 출력 결과의 형상에 영향을 주지 않으며\n",
        "\n",
        "형상이 다른 블록의 덧셈(필터의 결과 & 편향)이 가능한 이유는 앞선 넘파이의 브로드캐스트 기능 덕분이다\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "AJdoR748HT_A"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 배치 처리\n",
        "\n",
        "신경망 처리에서는 입력 데이터를 한 덩어리로 묶어 배치로 처리했다.\n",
        "\n",
        "완전연결 신경망에서 이 방식을 지원하였고, 합성곱 신경망에서도 이러한 배치 처리를 지원하고자 한다\n",
        "\n",
        "그래서 각 계층을 흐르는 데이터의 차원을 하나 늘려 4차원 데이터로 저장한다.\n",
        "\n",
        "데이터 : (데이터 수, 채널 수, 높이, 너비 )\n",
        "\n",
        "최종\n",
        "\n",
        "(**N**,C,H,W) * (FN,C,FH,FW) --> (**N**,FN,OH,OW)  <필터>\n",
        "\n",
        "(N,FN,OH,OW) + (FN,1,1) ---> (N,FN,OH,OW)  <편향>\n",
        "\n",
        "#정리\n",
        "\n",
        "✈ 3차원 데이터 (채널,높이,너비) 에는 고유의 \"정보\"가 들어간다\n",
        "\n",
        "✈ 3차원 데이터를 다루기 위해 완전연결 신경망이 아닌 합성곱 신경망을 이용한다\n",
        "\n",
        "✈ 배치 처리를 지원하는 합성곱 데이터는 4차원 형상을 가진채 각 계층을 타고 흐른다"
      ],
      "metadata": {
        "id": "0i_0-vfjc8VP"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_LXMvrMJHSns"
      },
      "outputs": [],
      "source": [
        ""
      ]
    }
  ]
}