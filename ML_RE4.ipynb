{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "ML_RE4.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyP344HpCH4lAo800bIozCYf",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/easyhardhoon/machine_learning_basic/blob/master/ML_RE4.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "✅ML8~ML9"
      ],
      "metadata": {
        "id": "sgGlJx_F4x7A"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**1. 역전파**"
      ],
      "metadata": {
        "id": "-vo7z1ee62xX"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**각 가중치 매개변수에 대한 손실함수의 기울기**가 핵심임은 분명하다.\n",
        "\n",
        "numerical_gradient는 명확하게 위의 개념이 도입되지만, \n",
        "\n",
        "gradient는 엄밀히 말하면 각 가중치 매개변수에 대한 (예측값- 정답레이블)의 기울기이다.\n",
        "\n",
        "아무튼 두 경우 모두 모델의 예측값과 정답 레이블의 오차를 줄이는데에 같은 뜻을 둔다.\n",
        "\n",
        "역전파의 경우 , 연쇄법칙 덕분에 구현이 가능하다. \n",
        "\n",
        "ex) dz/dx = dz/dt * dt/dx \n",
        "\n",
        "**기본적으로 역전파의 개념은 일단 입력 신호에 그 노드의 편미분을 곱하는 것이다**\n",
        "\n",
        "▶덧셈 노드 \n",
        "\n",
        "    ex) z  = x + y \n",
        "    dz/dx = dz/dy = 1 이므로 \n",
        "    역전파의 개념으로 보면 입력으로 들어온 dL/dz를 그대로 다음 노드로 보낸다\n",
        "\n",
        "▶곱셈 노드\n",
        "\n",
        "    ex) z = x * y\n",
        "    dz/dx = y, dz/dy = x이므로\n",
        "    상류의 값에 순전파 때의 입력 신호들을 서로 바꾼 값을 곱해서 하류로 보낸다\n",
        "    그렇기 떄문에 순전파의 입력신호의 값을 변수에 저장할 필요가 있다. "
      ],
      "metadata": {
        "id": "y9Su4c4Z652A"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "q_0VJvX84sxj"
      },
      "outputs": [],
      "source": [
        "class MulLayer:\n",
        "  def __init__(self):\n",
        "    self.x = None\n",
        "    self.y = None\n",
        "  def forward(self,x,y):\n",
        "    self.x = x\n",
        "    self.y = y\n",
        "    out = x * y\n",
        "    return out\n",
        "  def backward(self,dout):\n",
        "    dx = dout * self.y\n",
        "    dy = dout * self.x\n",
        "    return dx,dy\n",
        "class AddLayer:\n",
        "  def __init__(self):\n",
        "    pass\n",
        "  def forward(self,x,y):\n",
        "    out = x + y\n",
        "    return out\n",
        "  def backward(self,dout):\n",
        "    dx = dout * 1\n",
        "    dy = dout * 1\n",
        "    return dx,dy"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "지금까지는 각 계층이 단순 더하기나 곱하기 였지만 이제는 활성화 함수가 도입된다.\n",
        "\n",
        "(물론 각 활성화 함수를 세분화하면 더하기와 곱하기 같은 기본 단위로 나눌 수 있긴 하다)"
      ],
      "metadata": {
        "id": "uQ7sfPt7wMbk"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**2. 활성화함수**"
      ],
      "metadata": {
        "id": "9gCrEnK5yL5L"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "⚾Relu"
      ],
      "metadata": {
        "id": "tNlPyEDJyQkg"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np \n",
        "class Relu:\n",
        "  def __init__(self):\n",
        "    self.mask = None \n",
        "  def forward(self,x):\n",
        "    self.mask = (x<= 0)\n",
        "    out = x.copy()\n",
        "    out[self.mask] = 0\n",
        "    return out\n",
        "  def backward(self,dout):\n",
        "    dout[self.mask] = 0\n",
        "    dx = dout\n",
        "    return dx\n",
        "#같은 흐름의 x와 dout는 그 운명을 같이한다\n",
        "#Relu는 쉽게 __/ 모양이다. "
      ],
      "metadata": {
        "id": "yFa15O2xtXM9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "⚾Sigmoid"
      ],
      "metadata": {
        "id": "bmiWcZMC6dwG"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class Sigmoid:\n",
        "  def __init__(self):\n",
        "    self.out = None\n",
        "  def forward(self,x):\n",
        "    out = 1/(1+np.exp(-x))\n",
        "    self.out = out\n",
        "    return out\n",
        "  def backward(self,dout):\n",
        "    dx = dout * (1.0 - self.out) * self.out\n",
        "    return dx"
      ],
      "metadata": {
        "id": "_HF4Nn-26hOU"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "⚾Affine\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "IOA7eSNh7WHI"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class Affine:\n",
        "  def __init__(self,W,b):\n",
        "    #self로 저장한 변수들은 추후에 다 쓰인다\n",
        "    self.W = W \n",
        "    self.b = b \n",
        "    self.x = None \n",
        "    self.dw = None \n",
        "    self.db = None \n",
        "  def forward(self, x):\n",
        "    self.x = x\n",
        "    out = np.dot(x,self.W) + self.b\n",
        "    return out\n",
        "  def backward(self,dout):\n",
        "    #행렬곱 affine 역전파의 공식이다.\n",
        "    #행렬곱의 특성상 행렬에 대응하는 차원의 원소 수가 일치하도록 곱을 조립하는 것이 필요 (전치행렬사용)\n",
        "    dx  = np.dot(dout, self.W.T) \n",
        "    self.dW = np.dot(self.x.T, dout) \n",
        "    self.db = np.sum(dout, axis=0) \n",
        "    #배치크기가 1일경우, 즉 배치가 아닐 경우도 모두 통합시킨 코드.\n",
        "    return dx"
      ],
      "metadata": {
        "id": "h6caKi-a67Kd"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "⚡ 위 코드에서 self. db = np.sum(dout, axis=0)인 이유\n",
        "\n",
        "기본적으로 순전파의 흐름이 \n",
        "Y = np.dot(X,W) + B이고,\n",
        "\n",
        "계산 그래프의 원리를 잘 떠올려 역전파를 구해보면\n",
        "\n",
        "dB, 즉 편항의 기울기는 1차원형태의 배열로 저장되어져야 하고,\n",
        "\n",
        "덧셈 노드에 의해 dY의 값이 그대로 dB로 흘러들어옴을 알 수 있다.\n",
        "\n",
        "그렇기 때문에 2차원 형태였던 dY를 1차원으로 바꾸어주어야 하므로, 저러한 코드를 사용하였다\n",
        "\n"
      ],
      "metadata": {
        "id": "F-6vzIDTLOFc"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "dY = np.array([[1,2,3],[4,5,6]])\n",
        "dB = np.sum(dY,axis=0)\n",
        "dB"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kvJ9z2RHLRvL",
        "outputId": "8a7f3450-2241-4bad-a271-684e8c2d5248"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([5, 7, 9])"
            ]
          },
          "metadata": {},
          "execution_count": 2
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "이렇게 각 데이터 [1,2,3] 과 [4,5,6]이 합쳐져 하나의 데이터 형태로 바뀌는 모습\n",
        "\n",
        "다시 말해, 2차원 데이터가 1차원 데이터로 변환된 모습\n",
        "\n",
        "사실, 위 같은 코드는 **배치형태일때와 배치형태가 아닐때(데이터가 1개일 때) \n",
        "모든 경우를 고려해 통합한 코드**이다. (앞으로도 자주 사용.)"
      ],
      "metadata": {
        "id": "PHnjrEOfMltR"
      }
    }
  ]
}