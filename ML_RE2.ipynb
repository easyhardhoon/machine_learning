{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "ML_RE2.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyP5lIMT0+TXE0PqhL97Vq1D",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/easyhardhoon/machine_learning_basic/blob/master/ML_RE2.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "✅ML4~ML5"
      ],
      "metadata": {
        "id": "HiZhp5RHVd-8"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**1.mnist.py의 load_mnist에 대하여**"
      ],
      "metadata": {
        "id": "l31hJGH-Vk2I"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "flatten의 의미는?\n"
      ],
      "metadata": {
        "id": "7vqZ1mooh5W9"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MYqoe5NxVXRw",
        "outputId": "cffb1f96-5e88-450b-b18f-563a0d269274"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "x_train의 shape는 (60000, 784), t_train의 shape는 (60000,)입니다\n"
          ]
        }
      ],
      "source": [
        "from mnist import load_mnist\n",
        "(x_train,t_train), (x_test,t_test) = load_mnist(flatten=True, normalize=False)\n",
        "s1 = x_train.shape\n",
        "s2 = t_train.shape\n",
        "print(f\"x_train의 shape는 {s1}, t_train의 shape는 {s2}입니다\")"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from mnist import load_mnist\n",
        "(x_train,t_train), (x_test,t_test) = load_mnist(flatten=False, normalize=False)\n",
        "s2 = t_train.shape\n",
        "print(f\"x_train의 shape는 {s1}, t_train의 shape는 {s2}입니다\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZTK-FlOHXM_-",
        "outputId": "e23e6fdc-8ae5-4aef-af41-2a95c21d112a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "x_train의 shape는 (60000, 1, 28, 28), t_train의 shape는 (60000,)입니다\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "즉, 원래의 이미지 훈련 데이터(4차원)는 60,000개가 있고, \n",
        "\n",
        "각 데이터는 1개의 채널로 이루어져 있고 각 채널은 28*28크기로 이루어져 있다.\n",
        "\n",
        "이 4차원 데이터를 2차원으로 펴주는게 flatten = True이다."
      ],
      "metadata": {
        "id": "9YH4rnr9ZIaG"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "ex = np.array([[1],[2],[3]]) # (3,1)\n",
        "#ex.shape\n",
        "ex2 = np.array([2,3,4]) #(3,)\n",
        "ex2.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "a-zUq0JaYErN",
        "outputId": "2d207433-ad87-4519-9c37-7f65d2cbbfe4"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(3,)"
            ]
          },
          "metadata": {},
          "execution_count": 1
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "여기에서 추론할 수 있듯 t_train은, \n",
        "\n",
        "각 데이터마다의 정답 레이블이 기록된 곳이지만, \n",
        "\n",
        "오히려 1^x의 공간으로 이루어져 있음을 알 수 있다.\n",
        "\n",
        "⚡즉, 정답 레이블의 형태는 ㅣ 가 아니고 ㅡ 입니다.\n",
        "\n",
        "(default로 원핫인코딩이 false처리 되었을때)"
      ],
      "metadata": {
        "id": "sDaGxGsUaCig"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\"\"\"\n",
        "for i in range(len(x)):\n",
        "  y = predict(network, x[i]) \n",
        "  p = np.argmax(y) \n",
        "  if p == t[i]:      --------> 예측결과 확률 중 가장 높은 값의 인덱스와 정답 레이블 비교\n",
        "    accuracy_cnt += 1 \"\"\"\n",
        "print(\".\")\n",
        "#여기서 정답 레이블이 1차원형태의 배열임을 다시 한번 확인 가능합니다.\n",
        "#주의. 위 경우는 원핫인코딩이 false (디폴트)일 경우입니다. "
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KwuMIaJIZ6WO",
        "outputId": "b13c991d-5ffe-40a9-d887-50ba8fdb856a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            ".\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "그렇다면 normalize는 무엇을 의미할까요"
      ],
      "metadata": {
        "id": "efnDr9Tbf0NL"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from mnist import load_mnist\n",
        "(x_train,t_train), (x_test,t_test) = load_mnist(flatten=False, normalize=False)\n",
        "sample = x_train[0][0][14] #0번째 데이터의 0번째 채널의 14번째 행의 열들의 값\n",
        "sample"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Q0Mr_y-Pkm-G",
        "outputId": "59c57f14-70ee-4029-870d-2731f1e6a6b4"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
              "        81, 240, 253, 253, 119,  25,   0,   0,   0,   0,   0,   0,   0,\n",
              "         0,   0], dtype=uint8)"
            ]
          },
          "metadata": {},
          "execution_count": 37
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from mnist import load_mnist\n",
        "(x_train,t_train), (x_test,t_test) = load_mnist(flatten=False, normalize=True)\n",
        "sample = x_train[0][0][14]\n",
        "sample"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-hNntzJheyB1",
        "outputId": "2f5620f1-be7d-4a63-f49e-4234d477e89a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "       0.        , 0.        , 0.        , 0.31764707, 0.9411765 ,\n",
              "       0.99215686, 0.99215686, 0.46666667, 0.09803922, 0.        ,\n",
              "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "       0.        , 0.        , 0.        ], dtype=float32)"
            ]
          },
          "metadata": {},
          "execution_count": 34
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        " \n",
        " 이처럼 데이터를 특정 범위로 변환하는 처리를 정규화라고 한다.\n",
        "\n",
        "여기서는 픽셀값을 0~1로 변환하였다.\n",
        "\n",
        "이렇게 **신경망의 입력 데이터에 특정 변환을 가하는 것을 전처리**라고 합니다.\n",
        " \n",
        "\n",
        " "
      ],
      "metadata": {
        "id": "3aOQx-c8iETg"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "⚾정리하면\n",
        "\n",
        "load_mnist(flatten,normalize)에서 flatten과 normalize는 일종의 입력 데이터에 대한 전처리입니다.\n",
        "\n"
      ],
      "metadata": {
        "id": "5dbbY9ukgbFL"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "추가) one_hot_label은??\n"
      ],
      "metadata": {
        "id": "zuN3q7G6DN7F"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from mnist import load_mnist\n",
        "(x_train,t_train), (x_test,t_test) = load_mnist(flatten=False, normalize=False,one_hot_label=False)\n",
        "s1 = x_train.shape\n",
        "s2 = t_train.shape\n",
        "print(f\"t_train의 shape는 {s2}입니다\")\n",
        "print(t_train[0])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gE3J9IX2Dshv",
        "outputId": "3a92a040-a46c-4844-f2d7-3cddaadc6b2b"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "t_train의 shape는 (60000,)입니다\n",
            "5\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from mnist import load_mnist\n",
        "(x_train,t_train), (x_test,t_test) = load_mnist(flatten=False, normalize=False,one_hot_label=False)\n",
        "t_train"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VnpnHCKCME3U",
        "outputId": "a9c15ded-370a-4bf2-f4ef-6e1af4fb3d8f"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([5, 0, 4, ..., 5, 6, 8], dtype=uint8)"
            ]
          },
          "metadata": {},
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "---"
      ],
      "metadata": {
        "id": "SLrOzlyQQ8RV"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from mnist import load_mnist\n",
        "(x_train,t_train), (x_test,t_test) = load_mnist(flatten=False, normalize=False,one_hot_label=True)\n",
        "s1 = x_train.shape\n",
        "s2 = t_train.shape\n",
        "print(f\"t_train의 shape는 {s2}입니다\")\n",
        "print(t_train[0])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uNtN4oXwDNOW",
        "outputId": "de9cd332-16da-4e11-ac63-c1539df4f644"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "t_train의 shape는 (60000, 10)입니다\n",
            "[0. 0. 0. 0. 0. 1. 0. 0. 0. 0.]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from mnist import load_mnist\n",
        "(x_train,t_train), (x_test,t_test) = load_mnist(flatten=False, normalize=False,one_hot_label=True)\n",
        "t_train"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "G_Dg7hZRQ0mi",
        "outputId": "6654eca6-0bf8-4a91-e1dc-f51be03b2415"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[0., 0., 0., ..., 0., 0., 0.],\n",
              "       [1., 0., 0., ..., 0., 0., 0.],\n",
              "       [0., 0., 0., ..., 0., 0., 0.],\n",
              "       ...,\n",
              "       [0., 0., 0., ..., 0., 0., 0.],\n",
              "       [0., 0., 0., ..., 0., 0., 0.],\n",
              "       [0., 0., 0., ..., 0., 1., 0.]])"
            ]
          },
          "metadata": {},
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "---"
      ],
      "metadata": {
        "id": "rZOb5tHGQ-i6"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "위에서 보듯\n",
        "\n",
        "one_hot_label을 하게 되면 각 데이터마다의 정답 레이블이 원핫인코딩이 됨을 알 수 있다.\n",
        "\n",
        "즉, 원핫인코딩이 비활성화(default)되면 ㅡ 모양이지만\n",
        "\n",
        "활성화된다면 2차원 ㅣ 모양이 됩니다\n",
        "\n"
      ],
      "metadata": {
        "id": "hw2Fa72QD9MF"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**2.원핫인코딩의 여부에 따라 loss 및 학습 알고리즘의 흐름이 변하는가?**\n",
        "\n",
        "지금까지 내가 당연히 여겼던 정답 레이블의 형태는, 원핫인코딩이 이루어졌을때였다.\n",
        "\n",
        "배치형태의 input데이터에 대한 예측값과, \n",
        "\n",
        "데이터 마다의 정답이 있는 배열로 이루어진 정답 레이블간의 비교가 맞다고 생각하기 때문\n",
        "\n",
        "그런데 이는 원핫인코딩이 이루어졌을때에 대한 답이었습니다. \n",
        "\n",
        "그럼 원핫인코딩이 이루어지지 않았을때의 학습 알고리즘은 다를까?"
      ],
      "metadata": {
        "id": "FEjmWpuVNsNb"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\"\"\"\n",
        "for i in range(0, len(x), batch_size): # 간격 : batch_size \n",
        "  x_batch = x[i:i+batch_size]\n",
        "  y_batch = predict(network, x_batch)\n",
        "  p = np.argmax(y_batch, axis=1)\n",
        "  accuracy_cnt += np.sum(p == t[i:i+batch_size]) \n",
        "\"\"\"\n",
        "# 각 데이터 기준 최댓값을 뽑아내기 위해 argmax(y_batch, axis=1)을 사용한 모습\n",
        "# p와 t는 모두 ㅡ 자 형태의 1차원 배열임을 알 수 있다. \n",
        "# numpy 배열에서 논리연산의 결과로 bool 배열이 만들어짐을 기억.\n",
        "#이렇게 억지로 batch 형태로 수정하면 원핫인코딩이 false일때도 가능한모습\n",
        "#사실 위 코드는 원핫인코딩이 true일때도 성립하지 않을까...? \n",
        "#아니다. 최소한 저 코드에서는 t(정답 레이블)이 1차원 배열이어야만 한다"
      ],
      "metadata": {
        "id": "u1jHr3TlUo6b"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#시험코드. 2차원 배열의 argmax(axis=1)하면 몇차원 데이터가 나올까\n",
        "import numpy as np\n",
        "a = np.array([[1,2],[2,3],[4,5]])\n",
        "p = np.argmax(a, axis=1)\n",
        "p\n",
        "#armax(axis=1)을 하게 되면 1차원 배열 형식이 리턴된다.\n",
        "#즉 위 코드는 오로지 원핫인코딩이 false일때만 적용이 된다"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "baCmou4BjPyC",
        "outputId": "5e75d2ac-ccb6-4763-9e40-6a43e9b969b0"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([1, 1, 1])"
            ]
          },
          "metadata": {},
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**하지만**\n",
        "\n",
        "2차원 배열 input에서 x[0]은 0번쨰 데이터, x[1]은 1번쨰 데이터를 의미한다\n",
        "\n",
        "  또한 1차원 배열 label에서 y[0]은 0번째 데이터에 대한 정답값, \n",
        "  \n",
        "  y[1]은 1번째 데이터에 대한 정답값을 의미합니다.\n",
        "\n",
        "  즉, _[0]에 대한 데이터마다의 접근 방식은 같다고 할 수 있다"
      ],
      "metadata": {
        "id": "5omMTj_rrllp"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def cross_entropy_error(y,t):\n",
        "  if y.ndim == 1: # 데이터가 1차원일때. 다차원일떄를 고려한 코드, 즉 여러개가 batch로 한꺼번에 들어올때를 대비한 코드\n",
        "    t = t.reshape(1,t.size)\n",
        "    y = y.reshape(1,y.size)\n",
        "  batch_size = y.shape[0]\n",
        "  return -np.sum(np.log(y[np.arange(batch_size), t] + 1e-7)) / batch_size\n",
        "  # 정답 레이블이 원핫인코딩이 안되어있을때의 코드입니다\n",
        "\n",
        "  # 원핫인코딩일때 t가 0인 원소는 교차 엔트로피 오차도 0이었으므로 전체 로직은 변하지 않는다가 핵심\n",
        "  # 그러므로 여기서도 정답에 해당하는 신경망의 출력만으로 교차 엔트로피 오차를 구할수 있다가 핵심\n",
        "  # 그래서 ex) y[0,2], y[1,7], y[3,9] .. 의 값들(각 데이터 0 ,1 ,2 ...에서 정답에 해당하는 인덱스의 값 2, 7, 9 ....) 만 더해주면 됌. \n",
        "  # 최종적으로 구하는 것은 하나의 loss의 값이기 때문에 평균손실함수의 개념을 써서 batch_size로 나눔\n",
        "  # 이렇게 해서 구해진 하나의 loss.\n",
        "  # 교차 엔트로피 오차는 \"정답일때의\" 출력만으로만 이루어져있다"
      ],
      "metadata": {
        "id": "rTdLly-4sXlY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "즉, 원핫인코딩을 하든 안하든 기본적인 데이터의 값과 학습 알고리즘은 변하지 않습니다.\n",
        "\n",
        "loss(x,t)이나 accuracy(x,t)이나 gradient(x,t)이나, 학습코드전체로 봤을때 흐름은 같습니다.\n",
        "\n",
        "다만, 각 함수(loss, accuracy, gradient) 내부에서 원핫인코딩 여부에 따른 코드의 변화가 있을 가능성이 있다고 생각됩니다. \n",
        "\n",
        "**요약하면, 지금까지 봐왔고 앞으로 사용할 실전 학습용 코드들은, 원핫인코딩 여부에 관계없이 통일된 코드입니다.**"
      ],
      "metadata": {
        "id": "6_Io9qU7uLlQ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**3.loss함수**"
      ],
      "metadata": {
        "id": "_xTlTm3Um_Rc"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def sum_squares_error(y,t): #오차제곱합\n",
        "  return 0.5 * np.sum((y-t)**2) \n",
        "def cross_entropy_error(y,t): #교차 엔트로피 오차\n",
        "  delta = 1e-7\n",
        "  return -np.sum(t*np.log(y+delta)) "
      ],
      "metadata": {
        "id": "kBjVBUOHnBLX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "⚡loss함수의 인자에는 출력값과 정답 레이블이 들어갑니다.\n",
        "\n",
        "즉, 두 값을 비교하며 loss값을 누적한 뒤 **단 하나의 스칼라 값 형태로 loss값을 리턴**합니다"
      ],
      "metadata": {
        "id": "M1P2xi7yCNQS"
      }
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "yp2P09F7CYTX"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}